{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f16d6cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cKDTree\n",
      "File \u001b[0;32m~/miniconda3/envs/3.11env/lib/python3.11/site-packages/pandas/__init__.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     ArrowDtype,\n\u001b[1;32m     49\u001b[0m     Int8Dtype,\n\u001b[1;32m     50\u001b[0m     Int16Dtype,\n\u001b[1;32m     51\u001b[0m     Int32Dtype,\n\u001b[1;32m     52\u001b[0m     Int64Dtype,\n\u001b[1;32m     53\u001b[0m     UInt8Dtype,\n\u001b[1;32m     54\u001b[0m     UInt16Dtype,\n\u001b[1;32m     55\u001b[0m     UInt32Dtype,\n\u001b[1;32m     56\u001b[0m     UInt64Dtype,\n\u001b[1;32m     57\u001b[0m     Float32Dtype,\n\u001b[1;32m     58\u001b[0m     Float64Dtype,\n\u001b[1;32m     59\u001b[0m     CategoricalDtype,\n\u001b[1;32m     60\u001b[0m     PeriodDtype,\n\u001b[1;32m     61\u001b[0m     IntervalDtype,\n\u001b[1;32m     62\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     63\u001b[0m     StringDtype,\n\u001b[1;32m     64\u001b[0m     BooleanDtype,\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     NA,\n\u001b[1;32m     67\u001b[0m     isna,\n\u001b[1;32m     68\u001b[0m     isnull,\n\u001b[1;32m     69\u001b[0m     notna,\n\u001b[1;32m     70\u001b[0m     notnull,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     Index,\n\u001b[1;32m     73\u001b[0m     CategoricalIndex,\n\u001b[1;32m     74\u001b[0m     RangeIndex,\n\u001b[1;32m     75\u001b[0m     MultiIndex,\n\u001b[1;32m     76\u001b[0m     IntervalIndex,\n\u001b[1;32m     77\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     78\u001b[0m     DatetimeIndex,\n\u001b[1;32m     79\u001b[0m     PeriodIndex,\n\u001b[1;32m     80\u001b[0m     IndexSlice,\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     NaT,\n\u001b[1;32m     83\u001b[0m     Period,\n\u001b[1;32m     84\u001b[0m     period_range,\n\u001b[1;32m     85\u001b[0m     Timedelta,\n\u001b[1;32m     86\u001b[0m     timedelta_range,\n\u001b[1;32m     87\u001b[0m     Timestamp,\n\u001b[1;32m     88\u001b[0m     date_range,\n\u001b[1;32m     89\u001b[0m     bdate_range,\n\u001b[1;32m     90\u001b[0m     Interval,\n\u001b[1;32m     91\u001b[0m     interval_range,\n\u001b[1;32m     92\u001b[0m     DateOffset,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     to_numeric,\n\u001b[1;32m     95\u001b[0m     to_datetime,\n\u001b[1;32m     96\u001b[0m     to_timedelta,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     Flags,\n\u001b[1;32m     99\u001b[0m     Grouper,\n\u001b[1;32m    100\u001b[0m     factorize,\n\u001b[1;32m    101\u001b[0m     unique,\n\u001b[1;32m    102\u001b[0m     value_counts,\n\u001b[1;32m    103\u001b[0m     NamedAgg,\n\u001b[1;32m    104\u001b[0m     array,\n\u001b[1;32m    105\u001b[0m     Categorical,\n\u001b[1;32m    106\u001b[0m     set_eng_float_format,\n\u001b[1;32m    107\u001b[0m     Series,\n\u001b[1;32m    108\u001b[0m     DataFrame,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m~/miniconda3/envs/3.11env/lib/python3.11/site-packages/pandas/core/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     NaT,\n\u001b[1;32m      3\u001b[0m     Period,\n\u001b[1;32m      4\u001b[0m     Timedelta,\n\u001b[1;32m      5\u001b[0m     Timestamp,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ArrowDtype,\n\u001b[1;32m     11\u001b[0m     CategoricalDtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     PeriodDtype,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/3.11env/lib/python3.11/site-packages/pandas/_libs/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     NaT,\n\u001b[1;32m     21\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     iNaT,\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mmissing.pyx:42\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import argparse\n",
    "# we will read in data with pandas frame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa42dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define properties for plotting\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "from cycler import cycler\n",
    "\n",
    "def rgb(r,g,b):\n",
    "    return (float(r)/256.,float(g)/256.,float(b)/256.)\n",
    "\n",
    "cb2 = [rgb(31,120,180), rgb(255,127,0), rgb(51,160,44), rgb(227,26,28), \\\n",
    "       rgb(166,206,227), rgb(253,191,111), rgb(178,223,138), rgb(251,154,153)]\n",
    "\n",
    "rcParams['figure.figsize'] = (9,7)\n",
    "rcParams['figure.dpi'] = 50\n",
    "\n",
    "rcParams['lines.linewidth'] = 2\n",
    "\n",
    "rcParams['axes.prop_cycle'] = cycler('color', cb2)\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['axes.grid'] = False\n",
    "\n",
    "rcParams['patch.facecolor'] = cb2[0]\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "\n",
    "rcParams['font.size'] = 23\n",
    "rcParams['font.weight'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  print(\"ran on GPU\")\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_sample = np.genfromtxt('/content/drive/MyDrive/sample_0.7_75.txt')\n",
    "R_gal = phase_sample[:,0]\n",
    "X_gal = phase_sample[:,1]\n",
    "Y_gal = phase_sample[:,2]\n",
    "Z_gal = phase_sample[:,3]\n",
    "Vx_gal = phase_sample[:,4]\n",
    "Vy_gal = phase_sample[:,5]\n",
    "Vz_gal = phase_sample[:,6]\n",
    "weight_star = phase_sample[:,7]\n",
    "\n",
    "\n",
    "def vel_cartesian_to_galactic(pos, vel, err_p=0):\n",
    "\n",
    "  r = (pos[:,0]**2 + pos[:,1]**2 + pos[:,2]**2)**0.5\n",
    "  theta = np.arcsin(pos[:,2]/r)\n",
    "  phi = np.arctan2(pos[:,1], pos[:,0])\n",
    "\n",
    "  vr = np.cos(theta)*np.cos(phi)*vel[:,0] \\\n",
    "        +  np.cos(theta)*np.sin(phi)*vel[:,1] \\\n",
    "        +  np.sin(theta)*vel[:,2]\n",
    "\n",
    "  v_theta = -np.sin(theta)*np.cos(phi)*vel[:,0]\\\n",
    "            - np.sin(theta)*np.sin(phi)*vel[:,1]\\\n",
    "            + np.cos(theta)*vel[:,2]\n",
    "\n",
    "  v_phi = -np.sin(phi)*vel[:,0] + np.cos(phi)*vel[:,1]\n",
    "\n",
    "  return vr, v_theta, v_phi\n",
    "\n",
    "pos_gal = np.array([X_gal, Y_gal, Z_gal]).T\n",
    "vel_gal = np.array([Vx_gal, Vy_gal, Vz_gal]).T\n",
    "\n",
    "\n",
    "N_small = 50000\n",
    "idx = np.random.choice(len(R_gal), size=N_small, replace=False)\n",
    "pos_small = pos_gal[idx]\n",
    "vel_small = vel_gal[idx]\n",
    "v_r_small, v_theta_small, v_phi_small = vel_cartesian_to_galactic(pos_small, vel_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47970a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NormStats:\n",
    "  center: torch.Tensor  # [3]\n",
    "  scale: torch.Tensor         \n",
    "\n",
    "  def _scale_like(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    # Ensure scale is a tensor on the same device/dtype as x\n",
    "    return torch.as_tensor(self.scale, device=x.device, dtype=x.dtype)\n",
    "\n",
    "  def _center_like(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    # Ensure center is a tensor on the same device/dtype as x\n",
    "    return torch.as_tensor(self.center, device=x.device, dtype=x.dtype)\n",
    "\n",
    "  def normalize(self, x3: torch.Tensor) -> torch.Tensor:\n",
    "    s = self._scale_like(x3)\n",
    "    c = self._center_like(x3)\n",
    "    return (x3 - c) / (s + 1e-8)\n",
    "\n",
    "  def denormalize(self, x3_norm: torch.Tensor) -> torch.Tensor:\n",
    "    s = self._scale_like(x3_norm)\n",
    "    c = self._center_like(x3_norm)\n",
    "    return x3_norm * (s + 1e-8) + c\n",
    "\n",
    "\n",
    "def isotropic_stats(x: torch.Tensor, pct: float = 95.0) -> NormStats:\n",
    "  center = x.mean(dim=0)\n",
    "  #center = torch.zeros(3)\n",
    "  r = torch.sqrt(((x - center)**2).sum(dim=1))\n",
    "  # use a robust single scale (95th percentile or RMS)\n",
    "  scale = torch.quantile(r, pct/100.0)\n",
    "  return NormStats(center=center, scale=scale)\n",
    "\n",
    "\n",
    "class LBVDataset(Dataset):\n",
    "  \"\"\"Simple dataset for Nx4 array with columns [x, y, z].\"\"\"\n",
    "  def __init__(self, data_np: np.ndarray, norm: NormStats | None = None):\n",
    "    assert data_np.ndim == 2 and data_np.shape[1] == 3, \"Expect Nx3 array [x, y, z]\"\n",
    "    x = torch.tensor(data_np, dtype=torch.float32)\n",
    "    self.norm = isotropic_stats(x) if norm is None else norm\n",
    "    self.x = self.norm.normalize(x)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.x.shape[0]\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdfb679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Model: u_θ(x,t)\n",
    "# ------------------------------\n",
    "\n",
    "class Flow(nn.Module):\n",
    "  def __init__(self, hidden: int = 512, depth: int = 3, act: str = \"silu\"):\n",
    "    super().__init__()\n",
    "    Act = nn.ELU if act.lower() == \"elu\" else nn.SiLU\n",
    "    in_dim = 3 + 1 + 1  # (x,y,z) + r + t\n",
    "    out_dim = 3         # predict dx/dt on (x,y,z)\n",
    "    layers = [nn.Linear(in_dim, hidden), Act()]\n",
    "    for _ in range(depth - 1):\n",
    "      layers += [nn.Linear(hidden, hidden), Act()]\n",
    "    layers += [nn.Linear(hidden, out_dim)]\n",
    "    self.net = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "  def forward(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    # xt: [B,3]; t: [B,1]\n",
    "    rt = torch.sqrt((xt ** 2).sum(dim=1, keepdim=True))\n",
    "    return self.net(torch.cat([xt, rt, t], dim=-1))\n",
    "\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def step_heun(self, x: torch.Tensor, t0: float, t1: float, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"One Heun (midpoint/RK2) step from t0 to t1 for the ODE x' = u_θ(x,t).\"\"\"\n",
    "    B = x.shape[0]\n",
    "    t0_t = torch.full((B, 1), t0, device=device)\n",
    "    t1_t = torch.full((B, 1), t1, device=device)\n",
    "    dt = (t1 - t0)\n",
    "    k1 = self.forward(x, t0_t)\n",
    "    x_mid = x + 0.5 * dt * k1\n",
    "    k2 = self.forward(x_mid, 0.5 * (t0_t + t1_t))\n",
    "    return x + dt * k2\n",
    "  \n",
    "\n",
    "# ------------------------------\n",
    "# Training (straight-line CFM)\n",
    "# ------------------------------\n",
    "\n",
    "def make_r_weight_bins(train_ds, bins: int = 64):\n",
    "  \"\"\"Build (edges, inv_counts) from the *normalized* XYZ in train_ds.\n",
    "  Returns numpy arrays: edges (len=bins+1), inv (len=bins) normalized to mean≈1.\n",
    "  \"\"\"\n",
    "  with torch.no_grad():\n",
    "      x = train_ds.x  # [N, D], D=3/4/5 ... first 3 are XYZ\n",
    "      xyz = x[:, :3]\n",
    "      r = torch.sqrt((xyz ** 2).sum(dim=1)).cpu().numpy()\n",
    "  hist, edges = np.histogram(r, bins=bins, density=False)\n",
    "  hist = hist.astype(np.float64) + 1e-6  # Laplace smoothing to avoid zeros\n",
    "  inv = 1.0 / hist\n",
    "  inv /= inv.mean()  # keep average weight ~1\n",
    "  return edges, inv\n",
    "\n",
    "def r_weights_from_edges(x_batch: torch.Tensor, edges: np.ndarray, inv: np.ndarray,\n",
    "                         cap: float | None = 5.0) -> torch.Tensor:\n",
    "  \"\"\"Map x_batch (normalized coords, first 3 dims XYZ) to inverse-frequency weights by R.\n",
    "  Returns weights as a tensor on x_batch.device.\n",
    "  \"\"\"\n",
    "  xyz = x_batch[:, :3]\n",
    "  r = torch.sqrt((xyz ** 2).sum(dim=1)).detach().cpu().numpy()\n",
    "  idx = np.clip(np.digitize(r, edges) - 1, 0, len(inv) - 1)\n",
    "  w = inv[idx]\n",
    "  if cap is not None:\n",
    "      w = np.minimum(w, float(cap))\n",
    "  return torch.tensor(w, dtype=torch.float32, device=x_batch.device)\n",
    "\n",
    "def soft_barrier(r, lo, hi, k: float = 25.0, power: float = 1.0):\n",
    "  \"\"\"\n",
    "  Smooth penalty for r outside [lo, hi].\n",
    "  k     : sharpness of the barrier (larger = steeper near edges).\n",
    "  power : 1.0 for linear-like growth, 2.0 for quadratic growth.\n",
    "  Returns a tensor with same shape as r.\n",
    "  \"\"\"\n",
    "  # softplus(x) ≈ max(0,x) but smooth; divide by k to keep scale stable\n",
    "  below = F.softplus(k * (lo - r)) / k\n",
    "  above = F.softplus(k * (r - hi)) / k\n",
    "  pen = below + above\n",
    "  if power != 1.0:\n",
    "      pen = pen.pow(power)\n",
    "  return pen\n",
    "\n",
    "\n",
    "def train_cfm(\n",
    "  model: Flow,\n",
    "  loader: DataLoader,\n",
    "  epochs: int = 200,\n",
    "  lr: float = 2e-4,\n",
    "  wd: float = 2e-4,\n",
    "  device: str = \"cuda\",\n",
    "  ema_decay: float = 0.999,\n",
    "  max_batches_per_epoch: int | None = None,\n",
    "  # R-weighting controls (set edges/inv=None to disable)\n",
    "  edges: np.ndarray | None = None,\n",
    "  inv: np.ndarray | None = None,\n",
    "  w_cap: float | None = 5.0,\n",
    "  Rmin_phys: float | None = None,        # e.g. 60.0\n",
    "  Rmax_phys: float | None = None,        # e.g. 90.0 \n",
    "  #shell_jitter=0.02, \n",
    "  use_penalty=True, \n",
    "  lam=0.05,                     # overall weight for the barrier\n",
    "  k_barrier: float = 25.0,      # sharpness\n",
    "  power_barrier: float = 1.0,   # 1 or 2\n",
    "  norm: NormStats | None = None,         # pass the same norm you used for LBVDataset\n",
    "):\n",
    "  device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "  model.to(device)\n",
    "  opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "  sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "\n",
    "\n",
    "  # EMA shadow\n",
    "  ema_model = Flow(hidden=model.net[0].out_features, depth=(len(model.net)-1)//2, act=\"silu\")\n",
    "  ema_model.load_state_dict(model.state_dict())\n",
    "  ema_model.to(device)\n",
    "  for p in ema_model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "  def ema_update():\n",
    "    with torch.no_grad():\n",
    "      for p, pe in zip(model.parameters(), ema_model.parameters()):\n",
    "        pe.data.mul_(ema_decay).add_(p.data, alpha=1.0 - ema_decay)\n",
    "\n",
    "\n",
    "  beta = torch.distributions.Beta(2.0, 2.0)  # t ~ Beta(2,2)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def shell_prior_isotropic(B, device, r_sampler):\n",
    "    u = torch.randn(B,3,device=device); u = u/(u.norm(dim=1,keepdim=True)+1e-12)\n",
    "    r0 = r_sampler(B, device=device, jitter=0.0)\n",
    "    return u * r0\n",
    "  \n",
    "  @torch.no_grad()\n",
    "  def shell_prior_aligned(x1, device, r_sampler, dir_jitter=0.05):\n",
    "    B = x1.shape[0]\n",
    "    r0 = r_sampler(B, device=device, jitter=0.0)\n",
    "    u1 = x1 / (x1.norm(dim=1, keepdim=True) + 1e-12)\n",
    "    if dir_jitter>0:\n",
    "        eps = torch.randn_like(u1)\n",
    "        eps -= (eps*u1).sum(dim=1,keepdim=True)*u1\n",
    "        u = (u1 + dir_jitter*eps); u = u/(u.norm(dim=1,keepdim=True)+1e-12)\n",
    "    else:\n",
    "        u = u1\n",
    "    return u * r0\n",
    "\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for ep in range(1, epochs + 1):\n",
    "    running = 0.0\n",
    "    nbatches = 0\n",
    "\n",
    "    for bidx, x1 in enumerate(loader):\n",
    "      x1 = x1.to(device)\n",
    "      B = x1.shape[0]\n",
    "      # Gaussian prior in normalized space\n",
    "      p_align = 0.0\n",
    "      mask = (torch.rand(B, device=device) < p_align)\n",
    "      x0 = torch.empty_like(x1)\n",
    "      x0[ mask] = shell_prior_aligned (x1[mask], device, sample_r_from_data, dir_jitter=0.05)\n",
    "      x0[~mask] = shell_prior_isotropic((~mask).sum().item(), device, sample_r_from_data)\n",
    "      # Sample t ∈ (0,1)\n",
    "      t = beta.sample((B, 1)).to(device)         # t ~ Beta(2,2)\n",
    "\n",
    "      # Straight line interpolation and target\n",
    "      xt = (1.0 - t) * x0 + t * x1 # X_t\n",
    "      target = (x1 - x0) # u* = X1 - X0 (t-constant)\n",
    "\n",
    "      pred = model(xt, t)\n",
    "      err  = ((pred - target) ** 2).sum(dim=1)   # [B]\n",
    "\n",
    "      if edges is not None and inv is not None:\n",
    "        w = r_weights_from_edges(torch.cat([x1,\n",
    "                             torch.sqrt((x1**2).sum(dim=1, keepdim=True))], dim=1), edges, inv, cap=w_cap)\n",
    "        loss = (err * w).mean()\n",
    "      else:\n",
    "        loss = err.mean()\n",
    "      \n",
    "      flow_mse = loss\n",
    "\n",
    "      #loss = ((pred - target) ** 2).sum(dim=1).mean()\n",
    "      if use_penalty and (Rmin_phys is not None) and (Rmax_phys is not None):\n",
    "        xt_phys = norm.denormalize(xt)\n",
    "        r_xt_phys = torch.linalg.norm(xt_phys, dim=1)\n",
    "        pen = soft_barrier(r_xt_phys, Rmin_phys, Rmax_phys,\n",
    "                       k=k_barrier, power=power_barrier)\n",
    "        pen_mean = pen.mean()\n",
    "        loss = loss + lam * pen.mean()\n",
    "\n",
    "\n",
    "      opt.zero_grad(set_to_none=True)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      opt.step()\n",
    "      ema_update()\n",
    "\n",
    "      running += loss.item()\n",
    "      nbatches += 1\n",
    "\n",
    "      if max_batches_per_epoch and (bidx + 1) >= max_batches_per_epoch:\n",
    "        break\n",
    "\n",
    "    # Step scheduler ONLY if we actually did optimizer steps this epoch\n",
    "    sched.step()\n",
    "    if ep == 1 or ep % 10 == 0:\n",
    "      print(f\"[Epoch {ep:03d}] flow_mse={flow_mse.item():.6f} pen={pen_mean.item():.6f} \"\n",
    "          f\"lam={lam:.3f} total={loss.item():.6f} lr={sched.get_last_lr()[0]:.2e}\")\n",
    "      #print(f\"[Epoch {ep:03d}] loss={running/nbatches:.6f}, lr={sched.get_last_lr()[0]:.2e}\", flush=True)\n",
    "\n",
    "  return ema_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Sampling\n",
    "# ------------------------------\n",
    "@torch.no_grad()\n",
    "def sample(model: Flow, n: int, steps: int = 30, device: str = \"cuda\",\n",
    "           rmin: float = None, rmax: float = None, do_project: bool = True) -> torch.Tensor:\n",
    "  device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "  model.eval().to(device)\n",
    "\n",
    "  u = torch.randn(n, 3, device=device)\n",
    "  u = u / (u.norm(dim=1, keepdim=True) + 1e-12)\n",
    "  #r0 = torch.rand(n, 1, device=device) * (rmax - rmin) + rmin\n",
    "  r0 = sample_r_from_data(n, device=device, jitter=0.01) \n",
    "  x = u * r0\n",
    "\n",
    "  #ts = torch.linspace(0.0, 1.0, steps + 1, device=device)\n",
    "  ts = 0.5*(1 - torch.cos(torch.linspace(0, math.pi, steps+1, device=device)))\n",
    "  for i in range(steps):\n",
    "    x = model.step_heun(x, t0=float(ts[i].item()), t1=float(ts[i + 1].item()), device=device)\n",
    "\n",
    "    if do_project:\n",
    "      r = x.norm(dim=1, keepdim=True)\n",
    "      s = torch.clamp(r, min=rmin, max=rmax) / (r + 1e-12)\n",
    "      x = x * s\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadcc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Main\n",
    "# ------------------------------\n",
    "\n",
    "# Define parameters directly for Colab\n",
    "epochs = 80\n",
    "batch_size = 512\n",
    "#steps = 30\n",
    "device = \"cuda\"\n",
    "save_path = \"samples_xyzvb.csv\"\n",
    "shuffle_data = False # Or True, depending on desired behavior\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Load data - using already loaded data\n",
    "data_np = np.vstack((X_gal[idx],Y_gal[idx],Z_gal[idx])).T\n",
    "assert data_np.ndim == 2 and data_np.shape[1] == 3, \"Expect Nx3 array [X,Y,Z]\"\n",
    "train_np = data_np\n",
    "\n",
    "# Fit normalization on train\n",
    "tmp_ds = LBVDataset(train_np, norm=None)\n",
    "norm = tmp_ds.norm\n",
    "train_ds = LBVDataset(train_np, norm=norm)\n",
    "\n",
    "with torch.no_grad():\n",
    "  x_norm_all = train_ds.x                                 # [N,3] normalized xyz\n",
    "  r_all = torch.sqrt((x_norm_all**2).sum(dim=1)).cpu().numpy()     # normalized radii\n",
    "  rmin = float(r_all.min()) #* 0.995\n",
    "  rmax = float(r_all.max()) #* 1.005\n",
    "\n",
    "print(f\"r_min={rmin:.4f}, r_max={rmax:.4f}\")\n",
    "\n",
    "r_all_sorted = np.sort(r_all)\n",
    "def sample_r_from_data(B, device, jitter=0.0):\n",
    "  # inverse-CDF by random quantiles\n",
    "  u = np.clip(np.random.rand(B), 1e-3, 1-1e-3)  # avoid endpoints\n",
    "  rs = np.interp(u, np.linspace(0, 1, len(r_all_sorted)), r_all_sorted)\n",
    "  if jitter and jitter > 0:\n",
    "    rs = rs + jitter * np.random.randn(B)\n",
    "  rs = np.clip(rs, rmin, rmax)\n",
    "  return torch.tensor(rs, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "#edges, inv = make_r_weight_bins(train_ds, bins=64)\n",
    "edges, inv = None, None\n",
    "\n",
    "loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "# Model & training\n",
    "model = Flow(hidden=768, depth=5, act=\"silu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc294f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_model = train_cfm(model, loader, epochs=epochs, device=device, edges=edges, inv=inv, w_cap=1.5, Rmin_phys=60.0, Rmax_phys=90.0, use_penalty=True, lam=0.08, k_barrier=15.0, power_barrier=1.0, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52084b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample in normalized space and denormalize\n",
    "x_norm = sample(ema_model, n=50000, steps=300, device=device,\n",
    "                rmin=rmin, rmax=rmax, do_project=False)\n",
    "x_denorm = norm.denormalize(x_norm.cpu())   # [N,3]\n",
    "\n",
    "pos_out = x_denorm.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96493e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_small = np.sqrt(pos_small[:,0]**2+pos_small[:,1]**2+pos_small[:,2]**2)\n",
    "R_out = np.sqrt(pos_out[:,0]**2+pos_out[:,1]**2+pos_out[:,2]**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8502ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(R_small, bins=100, density=True, alpha=0.5, label='True')\n",
    "plt.hist(R_out, bins=100, density=True, alpha=0.5, label='Generated')\n",
    "plt.xlabel('R')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
